# Retrospectiva Sprint 1

---

## √çndice

1. [PROMPT 1](#prompt-1)

---

## PROMPT 1

### ROL
Act√∫a como un Analista de Retrospectivas experto en identificar malestares del equipo y proponer soluciones pr√°cticas y accionables.

### OBJETIVO
Identificar los malestares, problemas o fricciones expresados por los miembros del equipo durante el sprint y proponer acciones de mejora.

### TRANSCRIPCI√ìN
A continuaci√≥n recibir√°s una transcripci√≥n correspondiente a una reuni√≥n de Sprint Retrospective. El equipo est√° conformado por 6 componentes principales: Tester, Front, Back, Discovery, DevOps y Scrum Master. En esta reuni√≥n se encuentran los malestares experimentados durante la ejecuci√≥n del 1 sprint de un total de 4 sprints.

### ACCI√ìN
Crea una lista con los malestares as√≠ como sus posibles soluciones para que el equipo se comprometa a implementar en el pr√≥ximo sprint.

### FORMATO DE SALIDA
Usa un formato de tabla con dos columnas: el problema y la posible soluci√≥n.

---

**RESPUESTA:**

A continuaci√≥n se presenta la s√≠ntesis de malestares del Sprint 1 junto con acciones de mejora concretas y accionables, elaboradas a partir del an√°lisis completo de la retrospectiva.

El enfoque est√° en que el equipo se comprometa expl√≠citamente a implementar estas acciones en el Sprint 2, considerando que es el primer sprint y que el uso de IA introduce fricciones propias de adopci√≥n temprana.

### üìä Malestares del Sprint 1 y Acciones de Mejora

| Problema identificado | Posible soluci√≥n / Acci√≥n para el pr√≥ximo sprint |
|---|---|
| Exceso de confianza en la IA sin validaci√≥n humana suficiente | - Incorporar una revisi√≥n humana obligatoria entre cada fase (Prototipo ‚Üí HU ‚Üí Desarrollo ‚Üí Pruebas).<br>- Definir el rol compartido de "auditor de IA", donde todo el equipo valida que lo generado sea coherente antes de avanzar. |
| Poca revisi√≥n del prototipo antes de generar HU y c√≥digo | - Establecer un checkpoint obligatorio de revisi√≥n del prototipo antes de generar HU.<br>- Usar checklist: roles, flujos alternos, excepciones, paginaci√≥n, colores, estados y validaciones. |
| Prototipos poco expresivos para que la IA entienda casos complejos (ej. multirol) | - Enriquecer los prototipos con mayor expresividad visual (ej. m√∫ltiples roles seleccionados, colores activos, estados expl√≠citos).<br>- Complementar con anotaciones visuales o texto cuando el comportamiento no sea evidente. |
| Desalineaci√≥n entre prototipo y HU generadas por IA | - Generar HU exclusivamente a partir del prototipo validado.<br>- Validar que las HU reflejen fielmente lo que el prototipo muestra (ej. multirol, reglas de negocio). |
| Sobrecarga del Tester por gran volumen de HU y criterios de aceptaci√≥n | - Definir un porcentaje de pruebas automatizadas vs. manuales (ej. 70% automatizadas / 30% manuales).<br>- Priorizar pruebas cr√≠ticas manuales y reducir detalle innecesario en casos de prueba repetitivos. |
| Falsos positivos y negativos en pruebas automatizadas | - Complementar automatizaci√≥n con revisi√≥n manual focalizada.<br>- Documentar limitaciones conocidas de las herramientas de testing usadas (ej. Selenium). |
| Retrasos en la ejecuci√≥n de pruebas | - Acordar ventanas claras para testing dentro del sprint.<br>- Reducir HU activas simult√°neamente para no saturar al componente de testing. |
| Retrasos e inasistencias en los Dailys | - Definir y respetar un horario fijo para el Daily.<br>- Acordar una penalizaci√≥n ligera y simb√≥lica (ej. desayuno para el equipo) para reforzar el h√°bito. |
| Problemas t√©cnicos resueltos tarde por dependencia de una sola persona | - Definir un backup t√©cnico por componente para casos de indisponibilidad.<br>- Documentar brevemente soluciones t√©cnicas clave para facilitar reemplazos. |
| Falta de notificaci√≥n oportuna de cambios t√©cnicos | - Automatizar notificaciones por correo o canal com√∫n cada vez que haya un commit o cambio relevante en Front o Back.<br>- Asegurar que todo el equipo est√© en copia. |
| Cierre tard√≠o de tareas en la herramienta de gesti√≥n | - Establecer el cierre de tareas como parte del DoD.<br>- Recordatorio diario para cerrar tareas terminadas el mismo d√≠a. |
| Pocos artefactos de Discovery m√°s all√° del prototipo | - Complementar el prototipo con lineamientos escritos, flujos o notas clave cuando sea necesario.<br>- Recoger feedback de Front y Testing para enriquecer Discovery. |
| Falta de gu√≠as claras para mejorar el uso de IA en el proceso | - Crear un documento compartido de aprendizajes y recomendaciones sobre c√≥mo alimentar mejor a la IA (inputs, im√°genes, secuencia). |

---

### ‚úÖ Resultado esperado para el Sprint 2

Si el equipo implementa estas acciones:

- Se reduce el retrabajo causado por suposiciones de la IA.
- Mejora la alineaci√≥n entre Discovery, Desarrollo y Testing.
- Se evita el cuello de botella en QA.
- Se gana madurez en el uso de IA como acelerador, no como sustituto del criterio humano.

